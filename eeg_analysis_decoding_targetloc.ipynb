{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8837052-6497-4f8e-b1bd-3469f535412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is for decoding the left and right target in the probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b23457-4df6-423f-840e-f8808c909ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary libraries for decoding(categorical)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Memory\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import mne\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "from mne.decoding import (SlidingEstimator, GeneralizingEstimator, Scaler,\n",
    "                          cross_val_multiscore, LinearModel, get_coef,\n",
    "                          Vectorizer, CSP)\n",
    "from mne import (read_epochs, combine_evoked, write_evokeds)\n",
    "from mne.stats import bonferroni_correction, fdr_correction\n",
    "from mne import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f053aed-ed3a-4695-9c5a-720e010b2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the basic folder names and the location of the eeg datasets\n",
    "folder_name_eeg = \"E:\\\\SUMO_further_data_pack_zx\\\\N2pc_IEM\\\\new_results\\\\eeg_before_IEM\\\\\"\n",
    "folder_name_beh = \"E:\\\\SUMO_further_data_pack_zx\\\\N2pc_IEM\\\\new_results\\\\eeg_beh\\\\\"\n",
    "subject_name = ['SUMO_0102', 'SUMO_0104', 'SUMO_0105', 'SUMO_0106',\n",
    "                'SUMO_0108', 'SUMO_0111', 'SUMO_0114', 'SUMO_0120', \n",
    "                'SUMO_3001', 'SUMO_3015', 'SUMO_3017']\n",
    "\n",
    "# we used the probe as the eeg data sets\n",
    "individual_name_eeg_tail = '_before_iem_probe1.set'\n",
    "individual_name_beh_tail = '_beh_probe1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f444e-a7bf-4ea8-9885-e869891c72e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mean = np.empty([len(subject_name), 1000])\n",
    "for s in subject_name:\n",
    "    eeg_file_name = str(folder_name_eeg + s + individual_name_eeg_tail)\n",
    "    beh_file_name = str(folder_name_beh + s + individual_name_beh_tail)\n",
    "\n",
    "    # load eeg file to the mne workspace\n",
    "    eeg = mne.read_epochs_eeglab(eeg_file_name)\n",
    "\n",
    "    # load the csv beh file to the df\n",
    "    df = pd.read_csv(beh_file_name)\n",
    "\n",
    "    # copy the df to df2 for modification\n",
    "    df2 = df.copy()\n",
    "    df2 = df2[['type', 'epoch', 'targetlocation']]\n",
    "    df2 = df2[df2['type'] == 'S 51'].reset_index()\n",
    "\n",
    "    # change from 1-len(label) to 0 - len(label)-1(from MATLAB to python)\n",
    "    df2.epoch = df.epoch - 1\n",
    "\n",
    "    # load parameters for later decoding\n",
    "    number_of_cpu = joblib.cpu_count()\n",
    "    clf = make_pipeline(Scaler(eeg.info),\n",
    "                        Vectorizer(),\n",
    "                        LogisticRegression(solver='lbfgs'))\n",
    "    # CSP\n",
    "    csp = CSP(n_components=5, norm_trace=False, cov_est='concat', cov_method_params = dict)\n",
    "    clf_csp = make_pipeline(csp, LinearModel(LogisticRegression(solver='lbfgs')))\n",
    "    # Time_decoding\n",
    "    clf_1 = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs'))\n",
    "    time_decode = SlidingEstimator(clf_1, n_jobs=number_of_cpu, scoring='roc_auc', verbose=True)\n",
    "    \n",
    "    #print(df2.head())\n",
    "\n",
    "    eeg2 = eeg.get_data()\n",
    "    score = cross_val_multiscore (time_decode, eeg2, df2.targetlocation, cv = 10, n_jobs=number_of_cpu)\n",
    "    score_mean[subject_name.index(s)] = np.mean(score, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686410c7-f699-4877-a9fc-dd6bcd6bec57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = np.mean(score_mean, axis=0)\n",
    "plt.figure(figsize=(10, 6), dpi=80)\n",
    "plt.plot(eeg.times, q, 'r', label='Scene_post')\n",
    "#plt.errorbar(eeg.times, q_fil, er)\n",
    "xmin, xmax = plt.xlim()\n",
    "# plt.hlines(0.5, xmin, xmax, linestyle='--', colors='k',\n",
    "#            label='chance', linewidth=2)\n",
    "#plt.hlines(threshold_fdr_f_p, xmin, xmax, linestyle='--', colors='b',\n",
    "           #label='p=0.05 (FDR)', linewidth=2)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time (sec)\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.savefig(\"probe1_targetlocation.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.savefig(\"probe1_targetlocation.png\", format=\"png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(\"probe1_group_score.csv\", score_mean, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
